{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDfO9wSmEP1n"
   },
   "source": [
    "# **Import necessary modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5sx5bvnHpHMj",
    "outputId": "5e03da54-9b7d-44cd-d91a-85516eac7115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hkc-avhgpQvE"
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "root = '.'\n",
    "data_path = os.path.join(root, 'data', 'icml_face_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UGHmF9v9A3zk"
   },
   "outputs": [],
   "source": [
    "sys.path.append(root)\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IwLlO9jVBKYC"
   },
   "source": [
    "# **Define Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TNKNKjTvqB_p"
   },
   "outputs": [],
   "source": [
    "# Training constants\n",
    "# Prone to modifications\n",
    "batch_size = 128*2\n",
    "buffer_size = 10000\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlOUrSVTBUvd"
   },
   "source": [
    "# **Choice of Loss Functions and Optimizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a3JMhukupkJq"
   },
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "catagorical_crossentropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "kl_divergence_loss = tf.keras.losses.KLDivergence()\n",
    "\n",
    "# Optimizers\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "rmsprop_optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sVqX_VXpBcMi"
   },
   "source": [
    "# **Data Extraction and Conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8coNvOZlpTuZ"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(data_path)\n",
    "train_data = dataset[dataset[' Usage'] == 'Training']\n",
    "val_data = dataset[dataset[' Usage'] == 'PrivateTest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1rHYH0PDC_eF"
   },
   "outputs": [],
   "source": [
    "def train_data_gen():\n",
    "    for _, row in train_data.iterrows():\n",
    "        emotion = int(row.emotion)\n",
    "        onehot_emotion = np.eye(7)[emotion].T.reshape((7, 1))\n",
    "        image = np.fromstring(row[' pixels'], dtype=np.float32, sep=' ').reshape((48, 48, 1)) / 255.\n",
    "        yield (image, onehot_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XIHTJZ95pYYA"
   },
   "outputs": [],
   "source": [
    "def val_data_gen():\n",
    "    for _, row in val_data.iterrows():\n",
    "        emotion = int(row.emotion)\n",
    "        onehot_emotion = np.eye(7)[emotion].T.reshape((7, 1))\n",
    "        image = np.fromstring(row[' pixels'], dtype=np.float32, sep=' ').reshape((48, 48, 1)) / 255.\n",
    "        yield (image, onehot_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlhyazvXpau6"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(train_data_gen,\n",
    "                                               (tf.float32, tf.int32),\n",
    "                                               (tf.TensorShape([48, 48, 1]), tf.TensorShape([7, 1]))).shuffle(buffer_size).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_generator(val_data_gen,\n",
    "                                             (tf.float32, tf.int32),\n",
    "                                             (tf.TensorShape([48, 48, 1]), tf.TensorShape([7, 1]))).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBHv6JUWDKv_"
   },
   "source": [
    "# **Model Init and Compilation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "sTAycf4KqXiW",
    "outputId": "839cc2d2-3bff-44cf-ba66-aa33fa13045d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 48, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 23, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 23, 23, 128)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 23, 23, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              1639424   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 3,077,575\n",
      "Trainable params: 3,072,583\n",
      "Non-trainable params: 4,992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model().get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pfuTIe-8rX0W"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam_optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWSdvo4rDPqL"
   },
   "source": [
    "# **Method to plot accuracy variation throughout training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mck5hZDqR_J"
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_summary(history):\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.history['categorical_accuracy'], label='train')\n",
    "    plt.plot(history.history['val_categorical_accuracy'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KUz3cOP9LzF8"
   },
   "source": [
    "# **Callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8cpMRODIDl8g"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(os.path.join(root, 'weights', 'best_weights.h5'),\n",
    "                                      monitor='val_categorical_accuracy',\n",
    "                                      verbose=1,\n",
    "                                      save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "reducelr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy',\n",
    "                                                         factor=0.1,\n",
    "                                                         patience=5,\n",
    "                                                         min_delta=0.01,verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint_callback, reducelr_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6IfHhHWNDc3R"
   },
   "source": [
    "# **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QZ0qaIfir1yS",
    "outputId": "ddfef732-7881-404b-8d37-a77e7d6c0083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.30148, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 45s - loss: 1.6824 - categorical_accuracy: 0.3595 - val_loss: 1.8938 - val_categorical_accuracy: 0.3015\n",
      "Epoch 2/40\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.30148 to 0.31708, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 37s - loss: 1.4453 - categorical_accuracy: 0.4482 - val_loss: 1.8245 - val_categorical_accuracy: 0.3171\n",
      "Epoch 3/40\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.31708 to 0.38228, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 37s - loss: 1.3246 - categorical_accuracy: 0.4939 - val_loss: 1.6744 - val_categorical_accuracy: 0.3823\n",
      "Epoch 4/40\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.38228 to 0.50293, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 37s - loss: 1.2589 - categorical_accuracy: 0.5215 - val_loss: 1.3163 - val_categorical_accuracy: 0.5029\n",
      "Epoch 5/40\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.50293 to 0.51881, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 37s - loss: 1.2017 - categorical_accuracy: 0.5451 - val_loss: 1.3118 - val_categorical_accuracy: 0.5188\n",
      "Epoch 6/40\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.51881\n",
      "113/113 - 34s - loss: 1.1560 - categorical_accuracy: 0.5585 - val_loss: 1.3187 - val_categorical_accuracy: 0.5185\n",
      "Epoch 7/40\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.51881 to 0.54639, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 37s - loss: 1.1172 - categorical_accuracy: 0.5771 - val_loss: 1.2667 - val_categorical_accuracy: 0.5464\n",
      "Epoch 8/40\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.54639 to 0.54890, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 37s - loss: 1.0849 - categorical_accuracy: 0.5896 - val_loss: 1.2538 - val_categorical_accuracy: 0.5489\n",
      "Epoch 9/40\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.54890 to 0.55447, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 37s - loss: 1.0545 - categorical_accuracy: 0.6024 - val_loss: 1.1851 - val_categorical_accuracy: 0.5545\n",
      "Epoch 10/40\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.55447 to 0.58429, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 37s - loss: 1.0213 - categorical_accuracy: 0.6156 - val_loss: 1.1375 - val_categorical_accuracy: 0.5843\n",
      "Epoch 11/40\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.58429\n",
      "113/113 - 34s - loss: 0.9944 - categorical_accuracy: 0.6283 - val_loss: 1.3280 - val_categorical_accuracy: 0.5511\n",
      "Epoch 12/40\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.58429\n",
      "113/113 - 34s - loss: 0.9699 - categorical_accuracy: 0.6360 - val_loss: 1.2574 - val_categorical_accuracy: 0.5634\n",
      "Epoch 13/40\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy improved from 0.58429 to 0.58819, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 36s - loss: 0.9473 - categorical_accuracy: 0.6426 - val_loss: 1.1609 - val_categorical_accuracy: 0.5882\n",
      "Epoch 14/40\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy improved from 0.58819 to 0.58902, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 37s - loss: 0.9152 - categorical_accuracy: 0.6579 - val_loss: 1.1712 - val_categorical_accuracy: 0.5890\n",
      "Epoch 15/40\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.58902\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "113/113 - 34s - loss: 0.8969 - categorical_accuracy: 0.6680 - val_loss: 1.1569 - val_categorical_accuracy: 0.5890\n",
      "Epoch 16/40\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy improved from 0.58902 to 0.63054, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 37s - loss: 0.7773 - categorical_accuracy: 0.7147 - val_loss: 1.0209 - val_categorical_accuracy: 0.6305\n",
      "Epoch 17/40\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.63054\n",
      "113/113 - 34s - loss: 0.7319 - categorical_accuracy: 0.7303 - val_loss: 1.0336 - val_categorical_accuracy: 0.6264\n",
      "Epoch 18/40\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy improved from 0.63054 to 0.63472, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 38s - loss: 0.7122 - categorical_accuracy: 0.7388 - val_loss: 1.0395 - val_categorical_accuracy: 0.6347\n",
      "Epoch 19/40\n",
      "\n",
      "Epoch 00019: val_categorical_accuracy improved from 0.63472 to 0.63500, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 37s - loss: 0.7004 - categorical_accuracy: 0.7428 - val_loss: 1.0672 - val_categorical_accuracy: 0.6350\n",
      "Epoch 20/40\n",
      "\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.63500\n",
      "113/113 - 34s - loss: 0.6885 - categorical_accuracy: 0.7503 - val_loss: 1.0594 - val_categorical_accuracy: 0.6328\n",
      "Epoch 21/40\n",
      "\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.63500\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "113/113 - 34s - loss: 0.6750 - categorical_accuracy: 0.7543 - val_loss: 1.0642 - val_categorical_accuracy: 0.6303\n",
      "Epoch 22/40\n",
      "\n",
      "Epoch 00022: val_categorical_accuracy improved from 0.63500 to 0.63862, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 36s - loss: 0.6509 - categorical_accuracy: 0.7636 - val_loss: 1.0580 - val_categorical_accuracy: 0.6386\n",
      "Epoch 23/40\n",
      "\n",
      "Epoch 00023: val_categorical_accuracy improved from 0.63862 to 0.63918, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 36s - loss: 0.6456 - categorical_accuracy: 0.7640 - val_loss: 1.0592 - val_categorical_accuracy: 0.6392\n",
      "Epoch 24/40\n",
      "\n",
      "Epoch 00024: val_categorical_accuracy improved from 0.63918 to 0.63945, saving model to /content/drive/My Drive/Experimental Projects/Emotion Detection/weights/best_weights.h5\n",
      "113/113 - 36s - loss: 0.6428 - categorical_accuracy: 0.7669 - val_loss: 1.0602 - val_categorical_accuracy: 0.6395\n",
      "Epoch 25/40\n",
      "\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.63945\n",
      "113/113 - 33s - loss: 0.6429 - categorical_accuracy: 0.7639 - val_loss: 1.0599 - val_categorical_accuracy: 0.6389\n",
      "Epoch 26/40\n",
      "\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.63945\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "113/113 - 33s - loss: 0.6413 - categorical_accuracy: 0.7676 - val_loss: 1.0642 - val_categorical_accuracy: 0.6369\n",
      "Epoch 27/40\n",
      "\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.63945\n",
      "113/113 - 33s - loss: 0.6390 - categorical_accuracy: 0.7676 - val_loss: 1.0643 - val_categorical_accuracy: 0.6375\n",
      "Epoch 28/40\n",
      "\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.63945\n",
      "113/113 - 33s - loss: 0.6386 - categorical_accuracy: 0.7677 - val_loss: 1.0643 - val_categorical_accuracy: 0.6369\n",
      "Epoch 29/40\n",
      "\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.63945\n",
      "113/113 - 33s - loss: 0.6389 - categorical_accuracy: 0.7700 - val_loss: 1.0646 - val_categorical_accuracy: 0.6367\n",
      "Epoch 30/40\n",
      "\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.63945\n",
      "113/113 - 33s - loss: 0.6381 - categorical_accuracy: 0.7710 - val_loss: 1.0650 - val_categorical_accuracy: 0.6367\n",
      "Epoch 31/40\n",
      "\n",
      "Epoch 00031: val_categorical_accuracy did not improve from 0.63945\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "113/113 - 33s - loss: 0.6407 - categorical_accuracy: 0.7664 - val_loss: 1.0641 - val_categorical_accuracy: 0.6356\n",
      "Epoch 32/40\n",
      "\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.63945\n",
      "113/113 - 33s - loss: 0.6373 - categorical_accuracy: 0.7675 - val_loss: 1.0644 - val_categorical_accuracy: 0.6361\n",
      "Epoch 33/40\n",
      "\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.63945\n",
      "113/113 - 33s - loss: 0.6351 - categorical_accuracy: 0.7705 - val_loss: 1.0644 - val_categorical_accuracy: 0.6356\n",
      "Epoch 34/40\n",
      "\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.63945\n",
      "113/113 - 33s - loss: 0.6388 - categorical_accuracy: 0.7683 - val_loss: 1.0644 - val_categorical_accuracy: 0.6364\n",
      "Epoch 35/40\n",
      "\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.63945\n",
      "113/113 - 33s - loss: 0.6327 - categorical_accuracy: 0.7686 - val_loss: 1.0646 - val_categorical_accuracy: 0.6361\n",
      "Epoch 36/40\n",
      "\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.63945\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "113/113 - 33s - loss: 0.6394 - categorical_accuracy: 0.7678 - val_loss: 1.0643 - val_categorical_accuracy: 0.6361\n",
      "Epoch 37/40\n",
      "\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.63945\n",
      "113/113 - 33s - loss: 0.6361 - categorical_accuracy: 0.7692 - val_loss: 1.0644 - val_categorical_accuracy: 0.6364\n",
      "Epoch 38/40\n",
      "\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.63945\n",
      "113/113 - 33s - loss: 0.6383 - categorical_accuracy: 0.7691 - val_loss: 1.0644 - val_categorical_accuracy: 0.6358\n",
      "Epoch 39/40\n",
      "\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.63945\n",
      "113/113 - 33s - loss: 0.6379 - categorical_accuracy: 0.7669 - val_loss: 1.0641 - val_categorical_accuracy: 0.6356\n",
      "Epoch 40/40\n",
      "\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.63945\n",
      "113/113 - 33s - loss: 0.6393 - categorical_accuracy: 0.7671 - val_loss: 1.0643 - val_categorical_accuracy: 0.6364\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=40,\n",
    "                    verbose=2,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "9InLpMossoYs",
    "outputId": "a43af042-12c5-4f8a-b4bd-086b3d480c58"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy_summary(history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
